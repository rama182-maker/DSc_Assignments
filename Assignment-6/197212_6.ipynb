{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "197212_6",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Assignment 6**\n",
        "\n",
        "**Name : Ramakrishna Reddy Are**\n",
        "\n",
        "**Roll No. : 197212**\n",
        "\n",
        "**Section : BTech III year CSE-B**\n",
        "\n",
        "**Date : 05-03-2022**"
      ],
      "metadata": {
        "id": "1eg4O-D3YH1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "szs9zcE6MhT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Logistic Regression for Multiclass Classifcation**"
      ],
      "metadata": {
        "id": "dziVjcZqYOG5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "A7aYGbu_MiQV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "62MVGZTqYEZo"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import numpy as np                            \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Importing the dataset [Iris.csv](https://www.kaggle.com/uciml/iris)***"
      ],
      "metadata": {
        "id": "S84kWKhaNizc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "dataset=pd.read_csv(\"Iris.csv\")"
      ],
      "metadata": {
        "id": "SmD-PTpwYetH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the dataset\n",
        "print(dataset.head(5))                "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d35Cx7zGYx44",
        "outputId": "22c9ce7f-3008-4dd8-8d5d-f484c6e02a57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
            "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the dataset in required format\n",
        "# assigning values to independent and dependent variable\n",
        "X = dataset.iloc[:,1:-1]            \n",
        "Y = dataset.iloc[:,-1]              \n",
        "print(X)                            \n",
        "print(Y)                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dX7qwbEZGpY",
        "outputId": "1e078f64-bcc1-4e27-a032-c1a5e7ca1972"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0              5.1           3.5            1.4           0.2\n",
            "1              4.9           3.0            1.4           0.2\n",
            "2              4.7           3.2            1.3           0.2\n",
            "3              4.6           3.1            1.5           0.2\n",
            "4              5.0           3.6            1.4           0.2\n",
            "..             ...           ...            ...           ...\n",
            "145            6.7           3.0            5.2           2.3\n",
            "146            6.3           2.5            5.0           1.9\n",
            "147            6.5           3.0            5.2           2.0\n",
            "148            6.2           3.4            5.4           2.3\n",
            "149            5.9           3.0            5.1           1.8\n",
            "\n",
            "[150 rows x 4 columns]\n",
            "0         Iris-setosa\n",
            "1         Iris-setosa\n",
            "2         Iris-setosa\n",
            "3         Iris-setosa\n",
            "4         Iris-setosa\n",
            "            ...      \n",
            "145    Iris-virginica\n",
            "146    Iris-virginica\n",
            "147    Iris-virginica\n",
            "148    Iris-virginica\n",
            "149    Iris-virginica\n",
            "Name: Species, Length: 150, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the test data from class objects to integers\n",
        "noofclasses=Y.nunique()                                           # finding number of unique classes in the dataset\n",
        "encode=dict(zip(Y.unique(),range(noofclasses)))                   # encoding the classes with numbers\n",
        "def encoding(Y):                                                  # function to encode the dataset\n",
        "  for i in range(len(Y)):                                         \n",
        "    Y.iat[i]=encode[Y.iat[i]]                                     # encoding the class\n",
        "  NewY = pd.DataFrame(Y,dtype='int64')\n",
        "  return NewY                                                     # returning the dataset\n",
        "Y=encoding(Y)                                                     # calling the encoding function\n",
        "print(Y)                                                          # printing the values of Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONF2yXVZhkcW",
        "outputId": "163fc957-d1b0-422b-aa86-64168177788a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Species\n",
            "0          0\n",
            "1          0\n",
            "2          0\n",
            "3          0\n",
            "4          0\n",
            "..       ...\n",
            "145        2\n",
            "146        2\n",
            "147        2\n",
            "148        2\n",
            "149        2\n",
            "\n",
            "[150 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the dataset into train and test data as 70% and 30% respectively.\n",
        "X_train=X.sample(frac=0.7,random_state=0)                      \n",
        "X_test=X.drop(X_train.index)         \n",
        "Y_train=Y.iloc[X_train.index]                                   \n",
        "Y_test=Y.iloc[X_test.index]                               \n",
        "print(\"X Train\\n\",X_train)                                      \n",
        "print(\"Y Train\\n\",Y_train)                                      \n",
        "print(\"X test\\n\",X_test)                                        \n",
        "print(\"Y test\\n\",Y_test)                                     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX_NxOxKZL49",
        "outputId": "de39b3f1-f78e-4a01-8088-1ec3e298b93b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train\n",
            "      SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "114            5.8           2.8            5.1           2.4\n",
            "62             6.0           2.2            4.0           1.0\n",
            "33             5.5           4.2            1.4           0.2\n",
            "107            7.3           2.9            6.3           1.8\n",
            "7              5.0           3.4            1.5           0.2\n",
            "..             ...           ...            ...           ...\n",
            "38             4.4           3.0            1.3           0.2\n",
            "5              5.4           3.9            1.7           0.4\n",
            "53             5.5           2.3            4.0           1.3\n",
            "143            6.8           3.2            5.9           2.3\n",
            "105            7.6           3.0            6.6           2.1\n",
            "\n",
            "[105 rows x 4 columns]\n",
            "Y Train\n",
            "      Species\n",
            "114        2\n",
            "62         1\n",
            "33         0\n",
            "107        2\n",
            "7          0\n",
            "..       ...\n",
            "38         0\n",
            "5          0\n",
            "53         1\n",
            "143        2\n",
            "105        2\n",
            "\n",
            "[105 rows x 1 columns]\n",
            "X test\n",
            "      SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0              5.1           3.5            1.4           0.2\n",
            "9              4.9           3.1            1.5           0.1\n",
            "14             5.8           4.0            1.2           0.2\n",
            "19             5.1           3.8            1.5           0.3\n",
            "21             5.1           3.7            1.5           0.4\n",
            "23             5.1           3.3            1.7           0.5\n",
            "25             5.0           3.0            1.6           0.2\n",
            "28             5.2           3.4            1.4           0.2\n",
            "29             4.7           3.2            1.6           0.2\n",
            "31             5.4           3.4            1.5           0.4\n",
            "32             5.2           4.1            1.5           0.1\n",
            "34             4.9           3.1            1.5           0.1\n",
            "35             5.0           3.2            1.2           0.2\n",
            "36             5.5           3.5            1.3           0.2\n",
            "39             5.1           3.4            1.5           0.2\n",
            "47             4.6           3.2            1.4           0.2\n",
            "49             5.0           3.3            1.4           0.2\n",
            "55             5.7           2.8            4.5           1.3\n",
            "57             4.9           2.4            3.3           1.0\n",
            "58             6.6           2.9            4.6           1.3\n",
            "65             6.7           3.1            4.4           1.4\n",
            "67             5.8           2.7            4.1           1.0\n",
            "70             5.9           3.2            4.8           1.8\n",
            "72             6.3           2.5            4.9           1.5\n",
            "74             6.4           2.9            4.3           1.3\n",
            "75             6.6           3.0            4.4           1.4\n",
            "77             6.7           3.0            5.0           1.7\n",
            "79             5.7           2.6            3.5           1.0\n",
            "81             5.5           2.4            3.7           1.0\n",
            "82             5.8           2.7            3.9           1.2\n",
            "87             6.3           2.3            4.4           1.3\n",
            "88             5.6           3.0            4.1           1.3\n",
            "99             5.7           2.8            4.1           1.3\n",
            "103            6.3           2.9            5.6           1.8\n",
            "115            6.4           3.2            5.3           2.3\n",
            "117            7.7           3.8            6.7           2.2\n",
            "118            7.7           2.6            6.9           2.3\n",
            "122            7.7           2.8            6.7           2.0\n",
            "130            7.4           2.8            6.1           1.9\n",
            "131            7.9           3.8            6.4           2.0\n",
            "136            6.3           3.4            5.6           2.4\n",
            "138            6.0           3.0            4.8           1.8\n",
            "140            6.7           3.1            5.6           2.4\n",
            "142            5.8           2.7            5.1           1.9\n",
            "145            6.7           3.0            5.2           2.3\n",
            "Y test\n",
            "      Species\n",
            "0          0\n",
            "9          0\n",
            "14         0\n",
            "19         0\n",
            "21         0\n",
            "23         0\n",
            "25         0\n",
            "28         0\n",
            "29         0\n",
            "31         0\n",
            "32         0\n",
            "34         0\n",
            "35         0\n",
            "36         0\n",
            "39         0\n",
            "47         0\n",
            "49         0\n",
            "55         1\n",
            "57         1\n",
            "58         1\n",
            "65         1\n",
            "67         1\n",
            "70         1\n",
            "72         1\n",
            "74         1\n",
            "75         1\n",
            "77         1\n",
            "79         1\n",
            "81         1\n",
            "82         1\n",
            "87         1\n",
            "88         1\n",
            "99         1\n",
            "103        2\n",
            "115        2\n",
            "117        2\n",
            "118        2\n",
            "122        2\n",
            "130        2\n",
            "131        2\n",
            "136        2\n",
            "138        2\n",
            "140        2\n",
            "142        2\n",
            "145        2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the dataset [Standardization of the data]\n",
        "def standardize(X):\n",
        "  m=X.shape[0]\n",
        "  n=X.shape[1]\n",
        "  k=0\n",
        "  for i in X.columns:\n",
        "    mean=0                                                        # for mean of each column\n",
        "    sd=0                                                          # for standard deviation of each column\n",
        "    mean = np.mean(X[i])                                          # finding mean of each column\n",
        "    sd = np.sum((X[i]-mean)**2)                          \n",
        "    sd=sd/(m)\n",
        "    sd = np.sqrt(sd)                                              # finding standard deviation of each column\n",
        "    for j in range(m):\n",
        "      cell=X.iat[j,k]\n",
        "      X.iat[j,k]=(cell-mean)/sd                                   # replacing the data in the dataset with standardized value\n",
        "    k+=1\n",
        "  return X\n",
        "X_train=standardize(X_train)                                      # Standardizing X_train\n",
        "X_test=standardize(X_test)                                        # Standardizing X_test\n",
        "print(X_train)                                                   \n",
        "print(X_test)                                                     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9OATOATZyZU",
        "outputId": "c8a50095-7a0b-4bf6-9895-32c338ecef02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "114      -0.023714     -0.535796       0.746986      1.553325\n",
            "62        0.225284     -1.913557       0.105045     -0.315241\n",
            "33       -0.397211      2.678980      -1.412270     -1.382993\n",
            "107       1.843771     -0.306169       1.447285      0.752511\n",
            "7        -1.019706      0.841965      -1.353911     -1.382993\n",
            "..             ...           ...            ...           ...\n",
            "38       -1.766700     -0.076542      -1.470628     -1.382993\n",
            "5        -0.521710      1.990099      -1.237195     -1.116055\n",
            "53       -0.397211     -1.683930       0.105045      0.085166\n",
            "143       1.221276      0.382711       1.213852      1.419856\n",
            "105       2.217268     -0.076542       1.622359      1.152918\n",
            "\n",
            "[105 rows x 4 columns]\n",
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0    -9.173947e-01      0.946388      -1.196718     -1.168808\n",
            "9    -1.146743e+00     -0.005287      -1.142703     -1.297091\n",
            "14   -1.146743e-01      2.135982      -1.304746     -1.168808\n",
            "19   -9.173947e-01      1.660145      -1.142703     -1.040524\n",
            "21   -9.173947e-01      1.422226      -1.142703     -0.912240\n",
            "23   -9.173947e-01      0.470551      -1.034675     -0.783956\n",
            "25   -1.032069e+00     -0.243206      -1.088689     -1.168808\n",
            "28   -8.027204e-01      0.708469      -1.196718     -1.168808\n",
            "29   -1.376092e+00      0.232632      -1.088689     -1.168808\n",
            "31   -5.733717e-01      0.708469      -1.142703     -0.912240\n",
            "32   -8.027204e-01      2.373901      -1.142703     -1.297091\n",
            "34   -1.146743e+00     -0.005287      -1.142703     -1.297091\n",
            "35   -1.032069e+00      0.232632      -1.304746     -1.168808\n",
            "36   -4.586974e-01      0.946388      -1.250732     -1.168808\n",
            "39   -9.173947e-01      0.708469      -1.142703     -1.168808\n",
            "47   -1.490766e+00      0.232632      -1.196718     -1.168808\n",
            "49   -1.032069e+00      0.470551      -1.196718     -1.168808\n",
            "55   -2.293487e-01     -0.719043       0.477727      0.242314\n",
            "57   -1.146743e+00     -1.670719      -0.170445     -0.142538\n",
            "58    8.027204e-01     -0.481125       0.531741      0.242314\n",
            "65    9.173947e-01     -0.005287       0.423712      0.370598\n",
            "67   -1.146743e-01     -0.956962       0.261669     -0.142538\n",
            "70    2.037026e-15      0.232632       0.639770      0.883733\n",
            "72    4.586974e-01     -1.432800       0.693784      0.498881\n",
            "74    5.733717e-01     -0.481125       0.369698      0.242314\n",
            "75    8.027204e-01     -0.243206       0.423712      0.370598\n",
            "77    9.173947e-01     -0.243206       0.747798      0.755449\n",
            "79   -2.293487e-01     -1.194881      -0.062417     -0.142538\n",
            "81   -4.586974e-01     -1.670719       0.045612     -0.142538\n",
            "82   -1.146743e-01     -0.956962       0.153641      0.114030\n",
            "87    4.586974e-01     -1.908637       0.423712      0.242314\n",
            "88   -3.440230e-01     -0.243206       0.261669      0.242314\n",
            "99   -2.293487e-01     -0.719043       0.261669      0.242314\n",
            "103   4.586974e-01     -0.481125       1.071884      0.883733\n",
            "115   5.733717e-01      0.232632       0.909841      1.525151\n",
            "117   2.064138e+00      1.660145       1.666042      1.396868\n",
            "118   2.064138e+00     -1.194881       1.774071      1.525151\n",
            "122   2.064138e+00     -0.719043       1.666042      1.140300\n",
            "130   1.720115e+00     -0.719043       1.341956      1.012016\n",
            "131   2.293487e+00      1.660145       1.503999      1.140300\n",
            "136   4.586974e-01      0.708469       1.071884      1.653435\n",
            "138   1.146743e-01     -0.243206       0.639770      0.883733\n",
            "140   9.173947e-01     -0.005287       1.071884      1.653435\n",
            "142  -1.146743e-01     -0.956962       0.801813      1.012016\n",
            "145   9.173947e-01     -0.243206       0.855827      1.525151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# implementing Gradient Descent Algorithm for multiclass classification\n",
        "def GradientDescent(X,Y,alpha,epochs):\n",
        "  X = np.c_[np.ones(len(X),dtype='float64'),X]          # adding extra column ie., for x0=1\n",
        "  n = Y.iloc[:,0].nunique()                             # finding number of classes\n",
        "  theta = np.zeros((n,X.shape[1]))                      # initializing all the coefficients with 0s   \n",
        "  m = (int)(len(X))                                     # size of the training data\n",
        "  Y_temp = np.zeros((m,n))                              # stores the boolean value corresponding to whether it belongs to that class or not  \n",
        "  for i in range(len(Y)):\n",
        "    Y_temp[i][Y.iloc[i]]=1\n",
        "  for i in range(epochs):\n",
        "    pw = X.dot(theta.T)                                 # pw is theta times independent variable\n",
        "    h = np.exp(pw)/np.sum((np.exp(-pw)),axis=1)[:,None] # h is the expected value\n",
        "    pdtheta = X.T.dot(h-Y_temp)                         # value of partial derivative wrt theta                                  \n",
        "    theta = theta - alpha*pdtheta.T/m                   # updating the value of theta at every iteration\n",
        "  return theta                                          # returning the coefficients of xi"
      ],
      "metadata": {
        "id": "TrmuRru_amn9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "theta=GradientDescent(X_train,Y_train,0.01,1000)                                # calling Gradient Descent function and finding the values of theta\n",
        "def predict(X,theta):                                                           # function used to predict the value\n",
        "  X=np.c_[np.ones(len(X),dtype='float64'),X]                                    # adding extra column for X0\n",
        "  pw = X.dot(theta.T)                                                           # pw is theta times independent variable\n",
        "  h = np.exp(pw)/np.sum((np.exp(-pw)),axis=1)[:,None]                           # h is the expected value\n",
        "  Y_pred = np.argmax(h,axis=1)                                                  \n",
        "  Y_pred = np.asarray(Y_pred,dtype='int64')                                                 \n",
        "  return Y_pred                                                                 # returning the predicted values\n",
        "\n",
        "Y_pred=predict(X_test,theta)                                                    # finding the predicted values based on test data\n",
        "print(np.asarray(Y_test['Species']))                                            # printing test data\n",
        "print(Y_pred)                                                                   # printing predicted test data"
      ],
      "metadata": {
        "id": "OEylFGtOag5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9121d96d-2f18-4ee5-d20a-fb6df5580e59"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 2 1 2 2 2 2 2 1 1 1 1 1 1 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting the results\n",
        "def comp(Y1,Y2):                                                                # function to check number of correct predictions\n",
        "  Y1=np.asarray(Y1,dtype='int64')                                               # assigning Y1 as an array\n",
        "  Y2=np.asarray(Y2,dtype='int64')                                               # assigning Y2 as an array\n",
        "  correct=0                                                                     # variable for checking no of correct predictions\n",
        "  incorrect=0                                                                   # variable for checking no of incorrect predictions\n",
        "  for i in range(len(Y1)):                                                      \n",
        "    if(Y1[i]==Y2[i]):                                                           # if prediction is correct then correct++\n",
        "      correct+=1                                                                \n",
        "    else:                                                                       # if prediction is incorrect then correct++\n",
        "      incorrect+=1\n",
        "  correctperc=(correct*100)/len(Y1)                                             # percentage of correct predictions among all\n",
        "  return [correct,incorrect,correctperc]                                        # returning no of correct predictions,no of incorrect predictions,percentage of correct predicitons\n",
        "correct,incorrect,perc=comp(Y_test,Y_pred)                                      # calling the function to evaluate the model\n",
        "print(\"Correct Predictions : \",correct)                                         # printing number of correct predictions\n",
        "print(\"Incorrect Predictions : \",incorrect)                                     # printing number of incorrect predictions\n",
        "print(\"Percentage of correct prediction : \",perc)                               # printing the percentage of correct predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWvd4Hqo0_2S",
        "outputId": "fa612aad-9101-4f60-d3e0-e4bdafc389bd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct Predictions :  38\n",
            "Incorrect Predictions :  7\n",
            "Percentage of correct prediction :  84.44444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "wS7iMjA5NFeC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Support Vector Machines for Linear and Polynomial Kernel**"
      ],
      "metadata": {
        "id": "p0JNFdczVV-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "NPwAtrZcNGwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Linear Kernel***"
      ],
      "metadata": {
        "id": "WyZ8jgTbVkrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import numpy as np                            \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt               \n",
        "from cvxopt import matrix,solvers             \n",
        "import matplotlib"
      ],
      "metadata": {
        "id": "1dhQ94TKVn09"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Importing the dataset [Iris_twoclass](https://www.kaggle.com/uciml/iris)***"
      ],
      "metadata": {
        "id": "dB-aJcn8PpOR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "dataset=pd.read_csv(\"Iris_twoclass.csv\")    # 2 classes"
      ],
      "metadata": {
        "id": "JTixp9IOVuTX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the dataset\n",
        "print(dataset.head(5))                      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jN70dSlWrxe",
        "outputId": "f6491e98-1e4f-4451-e07e-06a8dd4d06e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
            "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the dataset in required format\n",
        "# assigning values to independent and dependent variable\n",
        "X = dataset.iloc[:,1:-1]         \n",
        "Y = dataset.iloc[:,-1]              \n",
        "print(X)                            \n",
        "print(Y)                           "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hteQIYNYWxKB",
        "outputId": "d97409cc-042c-4260-bd4e-a1e371195ae6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0             5.1           3.5            1.4           0.2\n",
            "1             4.9           3.0            1.4           0.2\n",
            "2             4.7           3.2            1.3           0.2\n",
            "3             4.6           3.1            1.5           0.2\n",
            "4             5.0           3.6            1.4           0.2\n",
            "..            ...           ...            ...           ...\n",
            "94            5.6           2.7            4.2           1.3\n",
            "95            5.7           3.0            4.2           1.2\n",
            "96            5.7           2.9            4.2           1.3\n",
            "97            6.2           2.9            4.3           1.3\n",
            "98            5.1           2.5            3.0           1.1\n",
            "\n",
            "[99 rows x 4 columns]\n",
            "0         Iris-setosa\n",
            "1         Iris-setosa\n",
            "2         Iris-setosa\n",
            "3         Iris-setosa\n",
            "4         Iris-setosa\n",
            "           ...       \n",
            "94    Iris-versicolor\n",
            "95    Iris-versicolor\n",
            "96    Iris-versicolor\n",
            "97    Iris-versicolor\n",
            "98    Iris-versicolor\n",
            "Name: Species, Length: 99, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the test data from class objects to integers\n",
        "noofclasses=Y.nunique()                                           # finding number of unique classes in the dataset\n",
        "labels=[1,-1]\n",
        "encode=dict(zip(Y.unique(),labels))                               # encoding the classes with numbers\n",
        "def encoding(Y):                                                  # function to encode the dataset\n",
        "  for i in range(len(Y)):                                         \n",
        "    Y.iat[i]=encode[Y.iat[i]]                                     # encoding the class\n",
        "  NewY = pd.DataFrame(Y,dtype='int64')\n",
        "  return NewY                                                     # returning the dataset\n",
        "Y=encoding(Y)                                                     # calling the encoding function\n",
        "print(Y)                                                          # printing the values of Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpnwo_8MW0aF",
        "outputId": "6443271f-35d4-46ed-b57d-38b109550cf8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Species\n",
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "4         1\n",
            "..      ...\n",
            "94       -1\n",
            "95       -1\n",
            "96       -1\n",
            "97       -1\n",
            "98       -1\n",
            "\n",
            "[99 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate the dataset into train and test data as 70% and 30% respectively.\n",
        "X_train=X.sample(frac=0.7,random_state=0)                     \n",
        "X_test=X.drop(X_train.index)                                   \n",
        "Y_train=Y.iloc[X_train.index]                                   \n",
        "Y_test=Y.iloc[X_test.index]                                    \n",
        "print(\"X Train\\n\",X_train)\n",
        "print(\"Y Train\\n\",Y_train)\n",
        "print(\"X test\\n\",X_test)                                      \n",
        "print(\"Y test\\n\",Y_test)                                        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H849UQIIW4hw",
        "outputId": "ac0efefb-e612-4823-e31f-e084df4e420c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X Train\n",
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "26            5.0           3.4            1.6           0.4\n",
            "86            6.7           3.1            4.7           1.5\n",
            "2             4.7           3.2            1.3           0.2\n",
            "55            5.7           2.8            4.5           1.3\n",
            "75            6.6           3.0            4.4           1.4\n",
            "..            ...           ...            ...           ...\n",
            "79            5.7           2.6            3.5           1.0\n",
            "85            6.0           3.4            4.5           1.6\n",
            "32            5.2           4.1            1.5           0.1\n",
            "84            5.4           3.0            4.5           1.5\n",
            "14            5.8           4.0            1.2           0.2\n",
            "\n",
            "[69 rows x 4 columns]\n",
            "Y Train\n",
            "     Species\n",
            "26        1\n",
            "86       -1\n",
            "2         1\n",
            "55       -1\n",
            "75       -1\n",
            "..      ...\n",
            "79       -1\n",
            "85       -1\n",
            "32        1\n",
            "84       -1\n",
            "14        1\n",
            "\n",
            "[69 rows x 1 columns]\n",
            "X test\n",
            "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "9             4.9           3.1            1.5           0.1\n",
            "12            4.8           3.0            1.4           0.1\n",
            "19            5.1           3.8            1.5           0.3\n",
            "20            5.4           3.4            1.7           0.2\n",
            "21            5.1           3.7            1.5           0.4\n",
            "25            5.0           3.0            1.6           0.2\n",
            "29            4.7           3.2            1.6           0.2\n",
            "36            5.5           3.5            1.3           0.2\n",
            "37            4.9           3.1            1.5           0.1\n",
            "39            5.1           3.4            1.5           0.2\n",
            "44            5.1           3.8            1.9           0.4\n",
            "46            5.1           3.8            1.6           0.2\n",
            "47            4.6           3.2            1.4           0.2\n",
            "49            5.0           3.3            1.4           0.2\n",
            "58            6.6           2.9            4.6           1.3\n",
            "64            5.6           2.9            3.6           1.3\n",
            "65            6.7           3.1            4.4           1.4\n",
            "67            5.8           2.7            4.1           1.0\n",
            "69            5.6           2.5            3.9           1.1\n",
            "70            5.9           3.2            4.8           1.8\n",
            "72            6.3           2.5            4.9           1.5\n",
            "77            6.7           3.0            5.0           1.7\n",
            "81            5.5           2.4            3.7           1.0\n",
            "83            6.0           2.7            5.1           1.6\n",
            "87            6.3           2.3            4.4           1.3\n",
            "88            5.6           3.0            4.1           1.3\n",
            "93            5.0           2.3            3.3           1.0\n",
            "95            5.7           3.0            4.2           1.2\n",
            "96            5.7           2.9            4.2           1.3\n",
            "97            6.2           2.9            4.3           1.3\n",
            "Y test\n",
            "     Species\n",
            "9         1\n",
            "12        1\n",
            "19        1\n",
            "20        1\n",
            "21        1\n",
            "25        1\n",
            "29        1\n",
            "36        1\n",
            "37        1\n",
            "39        1\n",
            "44        1\n",
            "46        1\n",
            "47        1\n",
            "49        1\n",
            "58       -1\n",
            "64       -1\n",
            "65       -1\n",
            "67       -1\n",
            "69       -1\n",
            "70       -1\n",
            "72       -1\n",
            "77       -1\n",
            "81       -1\n",
            "83       -1\n",
            "87       -1\n",
            "88       -1\n",
            "93       -1\n",
            "95       -1\n",
            "96       -1\n",
            "97       -1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the dataset [Standardization of the data]\n",
        "def standardize(X):\n",
        "  m=X.shape[0]\n",
        "  n=X.shape[1]\n",
        "  k=0\n",
        "  for i in X.columns:\n",
        "    mean=0                                                        # for mean of each column\n",
        "    sd=0                                                          # for standard deviation of each column\n",
        "    mean = np.mean(X[i])                                          # finding mean of each column\n",
        "    sd = np.sum((X[i]-mean)**2)                          \n",
        "    sd=sd/(m)\n",
        "    sd = np.sqrt(sd)                                              # finding standard deviation of each column\n",
        "    for j in range(m):\n",
        "      cell=X.iat[j,k]\n",
        "      X.iat[j,k]=(cell-mean)/sd                                   # replacing the data in the dataset with standardized value\n",
        "    k+=1\n",
        "  return X\n",
        "X_train=standardize(X_train)                                      # Standardizing X_train\n",
        "X_test=standardize(X_test)                                        # Standardizing X_test\n",
        "print(X_train)                                                 \n",
        "print(X_test)                                                    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXzuf3ILW77I",
        "outputId": "e8eea960-7ca2-4e0c-d6ca-ca5118011b2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "26      -0.679931      0.571062      -0.819250     -0.664130\n",
            "86       1.901166     -0.032049       1.325641      1.312634\n",
            "2       -1.135419      0.168988      -1.026820     -1.023542\n",
            "55       0.382874     -0.635161       1.187261      0.953222\n",
            "75       1.749337     -0.233087       1.118071      1.132928\n",
            "..            ...           ...            ...           ...\n",
            "79       0.382874     -1.037235       0.495361      0.414105\n",
            "85       0.838361      0.571062       1.187261      1.492339\n",
            "32      -0.376272      1.978323      -0.888440     -1.203247\n",
            "84      -0.072614     -0.233087       1.187261      1.312634\n",
            "14       0.534703      1.777285      -1.096010     -1.023542\n",
            "\n",
            "[69 rows x 4 columns]\n",
            "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "9       -1.033455      0.112147      -1.051241     -1.212784\n",
            "12      -1.201042     -0.128168      -1.121324     -1.212784\n",
            "19      -0.698280      1.794356      -1.051241     -0.867916\n",
            "20      -0.195519      0.833094      -0.911076     -1.040350\n",
            "21      -0.698280      1.554040      -1.051241     -0.695483\n",
            "25      -0.865868     -0.128168      -0.981158     -1.040350\n",
            "29      -1.368630      0.352463      -0.981158     -1.040350\n",
            "36      -0.027931      1.073409      -1.191407     -1.040350\n",
            "37      -1.033455      0.112147      -1.051241     -1.212784\n",
            "39      -0.698280      0.833094      -1.051241     -1.040350\n",
            "44      -0.698280      1.794356      -0.770910     -0.695483\n",
            "46      -0.698280      1.794356      -0.981158     -1.040350\n",
            "47      -1.536217      0.352463      -1.121324     -1.040350\n",
            "49      -0.865868      0.592778      -1.121324     -1.040350\n",
            "58       1.815529     -0.368484       1.121324      0.856421\n",
            "64       0.139656     -0.368484       0.420496      0.856421\n",
            "65       1.983116      0.112147       0.981158      1.028855\n",
            "67       0.474831     -0.849115       0.770910      0.339120\n",
            "69       0.139656     -1.329746       0.630745      0.511553\n",
            "70       0.642418      0.352463       1.261489      1.718589\n",
            "72       1.312767     -1.329746       1.331572      1.201288\n",
            "77       1.983116     -0.128168       1.401655      1.546156\n",
            "81      -0.027931     -1.570061       0.490579      0.339120\n",
            "83       0.810005     -0.849115       1.471738      1.373722\n",
            "87       1.312767     -1.810377       0.981158      0.856421\n",
            "88       0.139656     -0.128168       0.770910      0.856421\n",
            "93      -0.865868     -1.810377       0.210248      0.339120\n",
            "95       0.307243     -0.128168       0.840993      0.683987\n",
            "96       0.307243     -0.368484       0.840993      0.856421\n",
            "97       1.145180     -0.368484       0.911076      0.856421\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = X_train.to_numpy().shape[0]              \n",
        "H = np.dot(Y_train.to_numpy()*X_train.to_numpy(),(Y_train.to_numpy()*X_train.to_numpy()).T)     # Assigning Xi*Xj*Yi*Yj values to H   \n",
        "q = np.repeat([-1.0], n)[..., None]           \n",
        "A = Y_train.to_numpy().reshape(1, -1)         \n",
        "b = 0.0                                       \n",
        "G = np.negative(np.eye(n))                    \n",
        "h = np.zeros(n)\n",
        "P = matrix(H)\n",
        "q = matrix(q)\n",
        "G = matrix(G)\n",
        "h = matrix(h)\n",
        "A = matrix(A,(1,n),'d')\n",
        "A = matrix(A)\n",
        "b = matrix(b)\n",
        "sol = solvers.qp(P, q, G, h, A, b)\n",
        "alphas = np.array(sol[\"x\"])                  \n",
        "w = np.dot((Y_train.to_numpy() * alphas).T, X_train.to_numpy())[0]\n",
        "S = (alphas > 1e-5).flatten()\n",
        "b = np.mean(Y_train.to_numpy()[S]-np.dot(X_train.to_numpy()[S],w.reshape(-1,1)))\n",
        "print(\"W:\", w)                              \n",
        "print(\"b:\", b)                              "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJteTLE8cMLi",
        "outputId": "b33fe058-fdd7-4b86-8ddf-c6413dbf10fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.4551e+00 -4.2882e+00  1e+02  1e+01  2e+00\n",
            " 1: -1.2233e+00 -1.5154e+00  1e+01  8e-01  1e-01\n",
            " 2: -2.4491e-01 -1.0264e+00  8e-01  2e-16  7e-16\n",
            " 3: -5.0481e-01 -6.3428e-01  1e-01  1e-16  5e-16\n",
            " 4: -5.6690e-01 -6.3549e-01  7e-02  1e-16  4e-16\n",
            " 5: -6.1989e-01 -6.2168e-01  2e-03  8e-17  5e-16\n",
            " 6: -6.2128e-01 -6.2130e-01  2e-05  6e-17  6e-16\n",
            " 7: -6.2130e-01 -6.2130e-01  2e-07  1e-16  5e-16\n",
            "Optimal solution found.\n",
            "W: [-0.25477304  0.34665745 -0.69397903 -0.75888669]\n",
            "b: -0.15096714824959698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=w.dot(X_test.T)+b                                                        # predicting the value\n",
        "Y_pred[Y_pred<=0]=-1                                                            # replacing the value with respective labels\n",
        "Y_pred[Y_pred>=0]=1                                                             # replacing the value with respective labels\n",
        "print(Y_pred)                                                                   # printing the predicted label\n",
        "# predicting the results\n",
        "def comp(Y1,Y2):                                                                # function to check number of correct predictions\n",
        "  Y1=np.asarray(Y1,dtype='int64')                                               # assigning Y1 as an array\n",
        "  Y2=np.asarray(Y2,dtype='int64')                                               # assigning Y2 as an array\n",
        "  correct=0                                                                     # variable for checking no of correct predictions\n",
        "  incorrect=0                                                                   # variable for checking no of incorrect predictions\n",
        "  for i in range(len(Y1)):                                                      \n",
        "    if(Y1[i]==Y2[i]):                                                           # if prediction is correct then correct++\n",
        "      correct+=1                                                                \n",
        "    else:                                                                       # if prediction is incorrect then correct++\n",
        "      incorrect+=1\n",
        "  correctperc=(correct*100)/len(Y1)                                             # percentage of correct predictions among all\n",
        "  return [correct,incorrect,correctperc]                                        # returning no of correct predictions,no of incorrect predictions,percentage of correct predicitons\n",
        "correct,incorrect,perc=comp(Y_test,Y_pred)                                      # calling the function to evaluate the model\n",
        "print(\"Correct Predictions : \",correct)                                         # printing number of correct predictions\n",
        "print(\"Incorrect Predictions : \",incorrect)                                     # printing number of incorrect predictions\n",
        "print(\"Percentage of correct prediction : \",perc)                               # printing the percentage of correct predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdW4tbNzr_vW",
        "outputId": "ce073f15-235e-4ca1-8b0d-19d7fffdee6c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "Correct Predictions :  30\n",
            "Incorrect Predictions :  0\n",
            "Percentage of correct prediction :  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "w1-OHC2ONQkO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Polynomial Kernel***"
      ],
      "metadata": {
        "id": "kXPdAenit0Kt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "eQAUlEczNUke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing libraries\n",
        "import numpy as np                           \n",
        "import pandas as pd                          \n",
        "import matplotlib.pyplot as plt               \n",
        "from cvxopt import matrix,solvers             # importing cvxopt to optimize Convex Problem(ie., SVM)\n",
        "import matplotlib"
      ],
      "metadata": {
        "id": "Z9KyoFBAt5cb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading dataset\n",
        "dataset=pd.read_csv(\"Iris_twoclass.csv\")"
      ],
      "metadata": {
        "id": "aEMDoFs4uAzy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the dataset\n",
        "print(dataset.head(5))                   "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNZrfZCAuDm5",
        "outputId": "264dbbb3-d086-4a9c-8e60-66b92b9e53f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
            "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
            "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
            "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
            "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
            "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing the dataset in required format\n",
        "# assigning values to independent and dependent variable\n",
        "X = dataset.iloc[:,1:-1]            \n",
        "Y = dataset.iloc[:,-1]    \n",
        "print(X)                            \n",
        "print(Y)                        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww9RztFTuF2h",
        "outputId": "7fe2a0d4-9fbb-4aa0-d15b-a4d836d6f4dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
            "0             5.1           3.5            1.4           0.2\n",
            "1             4.9           3.0            1.4           0.2\n",
            "2             4.7           3.2            1.3           0.2\n",
            "3             4.6           3.1            1.5           0.2\n",
            "4             5.0           3.6            1.4           0.2\n",
            "..            ...           ...            ...           ...\n",
            "94            5.6           2.7            4.2           1.3\n",
            "95            5.7           3.0            4.2           1.2\n",
            "96            5.7           2.9            4.2           1.3\n",
            "97            6.2           2.9            4.3           1.3\n",
            "98            5.1           2.5            3.0           1.1\n",
            "\n",
            "[99 rows x 4 columns]\n",
            "0         Iris-setosa\n",
            "1         Iris-setosa\n",
            "2         Iris-setosa\n",
            "3         Iris-setosa\n",
            "4         Iris-setosa\n",
            "           ...       \n",
            "94    Iris-versicolor\n",
            "95    Iris-versicolor\n",
            "96    Iris-versicolor\n",
            "97    Iris-versicolor\n",
            "98    Iris-versicolor\n",
            "Name: Species, Length: 99, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(X)\n",
        "# for forming a polynomial using features\n",
        "def Polynomialdegree(X,n):                                                      # function to form a polynomial and return it\n",
        "  Y=np.ones(len(X))                                                             # Y is a temp array to return \n",
        "  for i in range(2,n+1):                                                        # Y is having all the arrays raised to the power\n",
        "    Y=np.c_[Y,X**i]\n",
        "  return Y                                                                      # Y is having the features raised to respective powers\n",
        "# forming features for given degree\n",
        "X=Polynomialdegree(X,3)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQNMyKvVu1PZ",
        "outputId": "e28925c4-6d2f-4b5e-a23b-517aff06474e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00000e+00 2.60100e+01 1.22500e+01 1.96000e+00 4.00000e-02 1.32651e+02\n",
            "  4.28750e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.40100e+01 9.00000e+00 1.96000e+00 4.00000e-02 1.17649e+02\n",
            "  2.70000e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.20900e+01 1.02400e+01 1.69000e+00 4.00000e-02 1.03823e+02\n",
            "  3.27680e+01 2.19700e+00 8.00000e-03]\n",
            " [1.00000e+00 2.11600e+01 9.61000e+00 2.25000e+00 4.00000e-02 9.73360e+01\n",
            "  2.97910e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.29600e+01 1.96000e+00 4.00000e-02 1.25000e+02\n",
            "  4.66560e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.91600e+01 1.52100e+01 2.89000e+00 1.60000e-01 1.57464e+02\n",
            "  5.93190e+01 4.91300e+00 6.40000e-02]\n",
            " [1.00000e+00 2.11600e+01 1.15600e+01 1.96000e+00 9.00000e-02 9.73360e+01\n",
            "  3.93040e+01 2.74400e+00 2.70000e-02]\n",
            " [1.00000e+00 2.50000e+01 1.15600e+01 2.25000e+00 4.00000e-02 1.25000e+02\n",
            "  3.93040e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 1.93600e+01 8.41000e+00 1.96000e+00 4.00000e-02 8.51840e+01\n",
            "  2.43890e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.40100e+01 9.61000e+00 2.25000e+00 1.00000e-02 1.17649e+02\n",
            "  2.97910e+01 3.37500e+00 1.00000e-03]\n",
            " [1.00000e+00 2.91600e+01 1.36900e+01 2.25000e+00 4.00000e-02 1.57464e+02\n",
            "  5.06530e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 2.30400e+01 1.15600e+01 2.56000e+00 4.00000e-02 1.10592e+02\n",
            "  3.93040e+01 4.09600e+00 8.00000e-03]\n",
            " [1.00000e+00 2.30400e+01 9.00000e+00 1.96000e+00 1.00000e-02 1.10592e+02\n",
            "  2.70000e+01 2.74400e+00 1.00000e-03]\n",
            " [1.00000e+00 1.84900e+01 9.00000e+00 1.21000e+00 1.00000e-02 7.95070e+01\n",
            "  2.70000e+01 1.33100e+00 1.00000e-03]\n",
            " [1.00000e+00 3.36400e+01 1.60000e+01 1.44000e+00 4.00000e-02 1.95112e+02\n",
            "  6.40000e+01 1.72800e+00 8.00000e-03]\n",
            " [1.00000e+00 3.24900e+01 1.93600e+01 2.25000e+00 1.60000e-01 1.85193e+02\n",
            "  8.51840e+01 3.37500e+00 6.40000e-02]\n",
            " [1.00000e+00 2.91600e+01 1.52100e+01 1.69000e+00 1.60000e-01 1.57464e+02\n",
            "  5.93190e+01 2.19700e+00 6.40000e-02]\n",
            " [1.00000e+00 2.60100e+01 1.22500e+01 1.96000e+00 9.00000e-02 1.32651e+02\n",
            "  4.28750e+01 2.74400e+00 2.70000e-02]\n",
            " [1.00000e+00 3.24900e+01 1.44400e+01 2.89000e+00 9.00000e-02 1.85193e+02\n",
            "  5.48720e+01 4.91300e+00 2.70000e-02]\n",
            " [1.00000e+00 2.60100e+01 1.44400e+01 2.25000e+00 9.00000e-02 1.32651e+02\n",
            "  5.48720e+01 3.37500e+00 2.70000e-02]\n",
            " [1.00000e+00 2.91600e+01 1.15600e+01 2.89000e+00 4.00000e-02 1.57464e+02\n",
            "  3.93040e+01 4.91300e+00 8.00000e-03]\n",
            " [1.00000e+00 2.60100e+01 1.36900e+01 2.25000e+00 1.60000e-01 1.32651e+02\n",
            "  5.06530e+01 3.37500e+00 6.40000e-02]\n",
            " [1.00000e+00 2.11600e+01 1.29600e+01 1.00000e+00 4.00000e-02 9.73360e+01\n",
            "  4.66560e+01 1.00000e+00 8.00000e-03]\n",
            " [1.00000e+00 2.60100e+01 1.08900e+01 2.89000e+00 2.50000e-01 1.32651e+02\n",
            "  3.59370e+01 4.91300e+00 1.25000e-01]\n",
            " [1.00000e+00 2.30400e+01 1.15600e+01 3.61000e+00 4.00000e-02 1.10592e+02\n",
            "  3.93040e+01 6.85900e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 9.00000e+00 2.56000e+00 4.00000e-02 1.25000e+02\n",
            "  2.70000e+01 4.09600e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.15600e+01 2.56000e+00 1.60000e-01 1.25000e+02\n",
            "  3.93040e+01 4.09600e+00 6.40000e-02]\n",
            " [1.00000e+00 2.70400e+01 1.22500e+01 2.25000e+00 4.00000e-02 1.40608e+02\n",
            "  4.28750e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 2.70400e+01 1.15600e+01 1.96000e+00 4.00000e-02 1.40608e+02\n",
            "  3.93040e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.20900e+01 1.02400e+01 2.56000e+00 4.00000e-02 1.03823e+02\n",
            "  3.27680e+01 4.09600e+00 8.00000e-03]\n",
            " [1.00000e+00 2.30400e+01 9.61000e+00 2.56000e+00 4.00000e-02 1.10592e+02\n",
            "  2.97910e+01 4.09600e+00 8.00000e-03]\n",
            " [1.00000e+00 2.91600e+01 1.15600e+01 2.25000e+00 1.60000e-01 1.57464e+02\n",
            "  3.93040e+01 3.37500e+00 6.40000e-02]\n",
            " [1.00000e+00 2.70400e+01 1.68100e+01 2.25000e+00 1.00000e-02 1.40608e+02\n",
            "  6.89210e+01 3.37500e+00 1.00000e-03]\n",
            " [1.00000e+00 3.02500e+01 1.76400e+01 1.96000e+00 4.00000e-02 1.66375e+02\n",
            "  7.40880e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.40100e+01 9.61000e+00 2.25000e+00 1.00000e-02 1.17649e+02\n",
            "  2.97910e+01 3.37500e+00 1.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.02400e+01 1.44000e+00 4.00000e-02 1.25000e+02\n",
            "  3.27680e+01 1.72800e+00 8.00000e-03]\n",
            " [1.00000e+00 3.02500e+01 1.22500e+01 1.69000e+00 4.00000e-02 1.66375e+02\n",
            "  4.28750e+01 2.19700e+00 8.00000e-03]\n",
            " [1.00000e+00 2.40100e+01 9.61000e+00 2.25000e+00 1.00000e-02 1.17649e+02\n",
            "  2.97910e+01 3.37500e+00 1.00000e-03]\n",
            " [1.00000e+00 1.93600e+01 9.00000e+00 1.69000e+00 4.00000e-02 8.51840e+01\n",
            "  2.70000e+01 2.19700e+00 8.00000e-03]\n",
            " [1.00000e+00 2.60100e+01 1.15600e+01 2.25000e+00 4.00000e-02 1.32651e+02\n",
            "  3.93040e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.22500e+01 1.69000e+00 9.00000e-02 1.25000e+02\n",
            "  4.28750e+01 2.19700e+00 2.70000e-02]\n",
            " [1.00000e+00 2.02500e+01 5.29000e+00 1.69000e+00 9.00000e-02 9.11250e+01\n",
            "  1.21670e+01 2.19700e+00 2.70000e-02]\n",
            " [1.00000e+00 1.93600e+01 1.02400e+01 1.69000e+00 4.00000e-02 8.51840e+01\n",
            "  3.27680e+01 2.19700e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.22500e+01 2.56000e+00 3.60000e-01 1.25000e+02\n",
            "  4.28750e+01 4.09600e+00 2.16000e-01]\n",
            " [1.00000e+00 2.60100e+01 1.44400e+01 3.61000e+00 1.60000e-01 1.32651e+02\n",
            "  5.48720e+01 6.85900e+00 6.40000e-02]\n",
            " [1.00000e+00 2.30400e+01 9.00000e+00 1.96000e+00 9.00000e-02 1.10592e+02\n",
            "  2.70000e+01 2.74400e+00 2.70000e-02]\n",
            " [1.00000e+00 2.60100e+01 1.44400e+01 2.56000e+00 4.00000e-02 1.32651e+02\n",
            "  5.48720e+01 4.09600e+00 8.00000e-03]\n",
            " [1.00000e+00 2.11600e+01 1.02400e+01 1.96000e+00 4.00000e-02 9.73360e+01\n",
            "  3.27680e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 2.80900e+01 1.36900e+01 2.25000e+00 4.00000e-02 1.48877e+02\n",
            "  5.06530e+01 3.37500e+00 8.00000e-03]\n",
            " [1.00000e+00 2.50000e+01 1.08900e+01 1.96000e+00 4.00000e-02 1.25000e+02\n",
            "  3.59370e+01 2.74400e+00 8.00000e-03]\n",
            " [1.00000e+00 4.90000e+01 1.02400e+01 2.20900e+01 1.96000e+00 3.43000e+02\n",
            "  3.27680e+01 1.03823e+02 2.74400e+00]\n",
            " [1.00000e+00 4.09600e+01 1.02400e+01 2.02500e+01 2.25000e+00 2.62144e+02\n",
            "  3.27680e+01 9.11250e+01 3.37500e+00]\n",
            " [1.00000e+00 4.76100e+01 9.61000e+00 2.40100e+01 2.25000e+00 3.28509e+02\n",
            "  2.97910e+01 1.17649e+02 3.37500e+00]\n",
            " [1.00000e+00 3.02500e+01 5.29000e+00 1.60000e+01 1.69000e+00 1.66375e+02\n",
            "  1.21670e+01 6.40000e+01 2.19700e+00]\n",
            " [1.00000e+00 4.22500e+01 7.84000e+00 2.11600e+01 2.25000e+00 2.74625e+02\n",
            "  2.19520e+01 9.73360e+01 3.37500e+00]\n",
            " [1.00000e+00 3.24900e+01 7.84000e+00 2.02500e+01 1.69000e+00 1.85193e+02\n",
            "  2.19520e+01 9.11250e+01 2.19700e+00]\n",
            " [1.00000e+00 3.96900e+01 1.08900e+01 2.20900e+01 2.56000e+00 2.50047e+02\n",
            "  3.59370e+01 1.03823e+02 4.09600e+00]\n",
            " [1.00000e+00 2.40100e+01 5.76000e+00 1.08900e+01 1.00000e+00 1.17649e+02\n",
            "  1.38240e+01 3.59370e+01 1.00000e+00]\n",
            " [1.00000e+00 4.35600e+01 8.41000e+00 2.11600e+01 1.69000e+00 2.87496e+02\n",
            "  2.43890e+01 9.73360e+01 2.19700e+00]\n",
            " [1.00000e+00 2.70400e+01 7.29000e+00 1.52100e+01 1.96000e+00 1.40608e+02\n",
            "  1.96830e+01 5.93190e+01 2.74400e+00]\n",
            " [1.00000e+00 2.50000e+01 4.00000e+00 1.22500e+01 1.00000e+00 1.25000e+02\n",
            "  8.00000e+00 4.28750e+01 1.00000e+00]\n",
            " [1.00000e+00 3.48100e+01 9.00000e+00 1.76400e+01 2.25000e+00 2.05379e+02\n",
            "  2.70000e+01 7.40880e+01 3.37500e+00]\n",
            " [1.00000e+00 3.60000e+01 4.84000e+00 1.60000e+01 1.00000e+00 2.16000e+02\n",
            "  1.06480e+01 6.40000e+01 1.00000e+00]\n",
            " [1.00000e+00 3.72100e+01 8.41000e+00 2.20900e+01 1.96000e+00 2.26981e+02\n",
            "  2.43890e+01 1.03823e+02 2.74400e+00]\n",
            " [1.00000e+00 3.13600e+01 8.41000e+00 1.29600e+01 1.69000e+00 1.75616e+02\n",
            "  2.43890e+01 4.66560e+01 2.19700e+00]\n",
            " [1.00000e+00 4.48900e+01 9.61000e+00 1.93600e+01 1.96000e+00 3.00763e+02\n",
            "  2.97910e+01 8.51840e+01 2.74400e+00]\n",
            " [1.00000e+00 3.13600e+01 9.00000e+00 2.02500e+01 2.25000e+00 1.75616e+02\n",
            "  2.70000e+01 9.11250e+01 3.37500e+00]\n",
            " [1.00000e+00 3.36400e+01 7.29000e+00 1.68100e+01 1.00000e+00 1.95112e+02\n",
            "  1.96830e+01 6.89210e+01 1.00000e+00]\n",
            " [1.00000e+00 3.84400e+01 4.84000e+00 2.02500e+01 2.25000e+00 2.38328e+02\n",
            "  1.06480e+01 9.11250e+01 3.37500e+00]\n",
            " [1.00000e+00 3.13600e+01 6.25000e+00 1.52100e+01 1.21000e+00 1.75616e+02\n",
            "  1.56250e+01 5.93190e+01 1.33100e+00]\n",
            " [1.00000e+00 3.48100e+01 1.02400e+01 2.30400e+01 3.24000e+00 2.05379e+02\n",
            "  3.27680e+01 1.10592e+02 5.83200e+00]\n",
            " [1.00000e+00 3.72100e+01 7.84000e+00 1.60000e+01 1.69000e+00 2.26981e+02\n",
            "  2.19520e+01 6.40000e+01 2.19700e+00]\n",
            " [1.00000e+00 3.96900e+01 6.25000e+00 2.40100e+01 2.25000e+00 2.50047e+02\n",
            "  1.56250e+01 1.17649e+02 3.37500e+00]\n",
            " [1.00000e+00 3.72100e+01 7.84000e+00 2.20900e+01 1.44000e+00 2.26981e+02\n",
            "  2.19520e+01 1.03823e+02 1.72800e+00]\n",
            " [1.00000e+00 4.09600e+01 8.41000e+00 1.84900e+01 1.69000e+00 2.62144e+02\n",
            "  2.43890e+01 7.95070e+01 2.19700e+00]\n",
            " [1.00000e+00 4.35600e+01 9.00000e+00 1.93600e+01 1.96000e+00 2.87496e+02\n",
            "  2.70000e+01 8.51840e+01 2.74400e+00]\n",
            " [1.00000e+00 4.62400e+01 7.84000e+00 2.30400e+01 1.96000e+00 3.14432e+02\n",
            "  2.19520e+01 1.10592e+02 2.74400e+00]\n",
            " [1.00000e+00 4.48900e+01 9.00000e+00 2.50000e+01 2.89000e+00 3.00763e+02\n",
            "  2.70000e+01 1.25000e+02 4.91300e+00]\n",
            " [1.00000e+00 3.60000e+01 8.41000e+00 2.02500e+01 2.25000e+00 2.16000e+02\n",
            "  2.43890e+01 9.11250e+01 3.37500e+00]\n",
            " [1.00000e+00 3.24900e+01 6.76000e+00 1.22500e+01 1.00000e+00 1.85193e+02\n",
            "  1.75760e+01 4.28750e+01 1.00000e+00]\n",
            " [1.00000e+00 3.02500e+01 5.76000e+00 1.44400e+01 1.21000e+00 1.66375e+02\n",
            "  1.38240e+01 5.48720e+01 1.33100e+00]\n",
            " [1.00000e+00 3.02500e+01 5.76000e+00 1.36900e+01 1.00000e+00 1.66375e+02\n",
            "  1.38240e+01 5.06530e+01 1.00000e+00]\n",
            " [1.00000e+00 3.36400e+01 7.29000e+00 1.52100e+01 1.44000e+00 1.95112e+02\n",
            "  1.96830e+01 5.93190e+01 1.72800e+00]\n",
            " [1.00000e+00 3.60000e+01 7.29000e+00 2.60100e+01 2.56000e+00 2.16000e+02\n",
            "  1.96830e+01 1.32651e+02 4.09600e+00]\n",
            " [1.00000e+00 2.91600e+01 9.00000e+00 2.02500e+01 2.25000e+00 1.57464e+02\n",
            "  2.70000e+01 9.11250e+01 3.37500e+00]\n",
            " [1.00000e+00 3.60000e+01 1.15600e+01 2.02500e+01 2.56000e+00 2.16000e+02\n",
            "  3.93040e+01 9.11250e+01 4.09600e+00]\n",
            " [1.00000e+00 4.48900e+01 9.61000e+00 2.20900e+01 2.25000e+00 3.00763e+02\n",
            "  2.97910e+01 1.03823e+02 3.37500e+00]\n",
            " [1.00000e+00 3.96900e+01 5.29000e+00 1.93600e+01 1.69000e+00 2.50047e+02\n",
            "  1.21670e+01 8.51840e+01 2.19700e+00]\n",
            " [1.00000e+00 3.13600e+01 9.00000e+00 1.68100e+01 1.69000e+00 1.75616e+02\n",
            "  2.70000e+01 6.89210e+01 2.19700e+00]\n",
            " [1.00000e+00 3.02500e+01 6.25000e+00 1.60000e+01 1.69000e+00 1.66375e+02\n",
            "  1.56250e+01 6.40000e+01 2.19700e+00]\n",
            " [1.00000e+00 3.02500e+01 6.76000e+00 1.93600e+01 1.44000e+00 1.66375e+02\n",
            "  1.75760e+01 8.51840e+01 1.72800e+00]\n",
            " [1.00000e+00 3.72100e+01 9.00000e+00 2.11600e+01 1.96000e+00 2.26981e+02\n",
            "  2.70000e+01 9.73360e+01 2.74400e+00]\n",
            " [1.00000e+00 3.36400e+01 6.76000e+00 1.60000e+01 1.44000e+00 1.95112e+02\n",
            "  1.75760e+01 6.40000e+01 1.72800e+00]\n",
            " [1.00000e+00 2.50000e+01 5.29000e+00 1.08900e+01 1.00000e+00 1.25000e+02\n",
            "  1.21670e+01 3.59370e+01 1.00000e+00]\n",
            " [1.00000e+00 3.13600e+01 7.29000e+00 1.76400e+01 1.69000e+00 1.75616e+02\n",
            "  1.96830e+01 7.40880e+01 2.19700e+00]\n",
            " [1.00000e+00 3.24900e+01 9.00000e+00 1.76400e+01 1.44000e+00 1.85193e+02\n",
            "  2.70000e+01 7.40880e+01 1.72800e+00]\n",
            " [1.00000e+00 3.24900e+01 8.41000e+00 1.76400e+01 1.69000e+00 1.85193e+02\n",
            "  2.43890e+01 7.40880e+01 2.19700e+00]\n",
            " [1.00000e+00 3.84400e+01 8.41000e+00 1.84900e+01 1.69000e+00 2.38328e+02\n",
            "  2.43890e+01 7.95070e+01 2.19700e+00]\n",
            " [1.00000e+00 2.60100e+01 6.25000e+00 9.00000e+00 1.21000e+00 1.32651e+02\n",
            "  1.56250e+01 2.70000e+01 1.33100e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the data from class objects to integers\n",
        "noofclasses=Y.nunique()                                           # finding number of unique classes in the dataset\n",
        "labels=[1,-1]\n",
        "encode=dict(zip(Y.unique(),labels))                               # encoding the classes with numbers\n",
        "def encoding(Y):                                                  # function to encode the dataset\n",
        "  for i in range(len(Y)):                                         \n",
        "    Y.iat[i]=encode[Y.iat[i]]                                     # encoding the class\n",
        "  NewY = pd.DataFrame(Y,dtype='int64')\n",
        "  return NewY                                                     # returning the dataset\n",
        "Y=encoding(Y)                                                     # calling the encoding function\n",
        "print(Y)                                                          # printing the values of Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhy5qyUOuISd",
        "outputId": "90166b2e-3254-478d-eff8-25f58f702ca9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Species\n",
            "0         1\n",
            "1         1\n",
            "2         1\n",
            "3         1\n",
            "4         1\n",
            "..      ...\n",
            "94       -1\n",
            "95       -1\n",
            "96       -1\n",
            "97       -1\n",
            "98       -1\n",
            "\n",
            "[99 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the dataset [Standardization of the data]\n",
        "def standardize(X):\n",
        "  # standardizing the dataset\n",
        "  m=len(X)\n",
        "  n=X.shape[1]\n",
        "  for i in range(n):\n",
        "    mean=0                                                        # for mean of each column\n",
        "    sd=0                                                          # for standard deviation of each column\n",
        "    for j in range(m):\n",
        "      mean+=X[j][i]\n",
        "    mean = mean/m                                                 # finding mean of each column\n",
        "    for j in range(m):\n",
        "      sd+=((X[j][i]-mean)**2)                          \n",
        "    sd=sd/(m-1)\n",
        "    sd = np.sqrt(sd)                                              # finding standard deviation of each column\n",
        "    for j in range(m):\n",
        "      cell=X[j][i]\n",
        "      if(sd>0):\n",
        "        X[j][i]=(cell-mean)/sd                                    # replacing the data in the dataset with standardized value\n",
        "  return X\n",
        "X=standardize(X)\n",
        "print(X)                                                          # printing X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvMeHV-uSJO",
        "outputId": "82fa58df-c949-4fe1-cc91-122eea612429"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.         -0.59522449  0.80769533 -0.95742386 -0.93700995 -0.61094151\n",
            "   0.7516471  -0.91159175 -0.8506143 ]\n",
            " [ 1.         -0.87157324 -0.27121019 -0.95742386 -0.93700995 -0.85369591\n",
            "  -0.32765441 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -1.13686804  0.14043376 -0.98878692 -0.93700995 -1.0774209\n",
            "   0.06449747 -0.92450258 -0.8506143 ]\n",
            " [ 1.         -1.2653702  -0.06870792 -0.92373761 -0.93700995 -1.1823901\n",
            "  -0.13790131 -0.89669827 -0.8506143 ]\n",
            " [ 1.         -0.73478061  1.04339469 -0.95742386 -0.93700995 -0.73474593\n",
            "   1.00870782 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -0.15997522  1.79032928 -0.84939556 -0.81010984 -0.20943071\n",
            "   1.86963349 -0.86039688 -0.81208774]\n",
            " [ 1.         -1.2653702   0.57863539 -0.95742386 -0.8841349  -1.1823901\n",
            "   0.50886375 -0.91159175 -0.83754279]\n",
            " [ 1.         -0.73478061  0.57863539 -0.92373761 -0.93700995 -0.73474593\n",
            "   0.50886375 -0.89669827 -0.8506143 ]\n",
            " [ 1.         -1.51408407 -0.46707304 -0.95742386 -0.93700995 -1.37902731\n",
            "  -0.50516976 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -0.87157324 -0.06870792 -0.92373761 -0.96873498 -0.85369591\n",
            "  -0.13790131 -0.89669827 -0.85543012]\n",
            " [ 1.         -0.15997522  1.28573347 -0.92373761 -0.93700995 -0.20943071\n",
            "   1.28045384 -0.89669827 -0.8506143 ]\n",
            " [ 1.         -1.00560238  0.57863539 -0.88772818 -0.93700995 -0.96788854\n",
            "   0.50886375 -0.87968052 -0.8506143 ]\n",
            " [ 1.         -1.00560238 -0.27121019 -0.95742386 -0.96873498 -0.96788854\n",
            "  -0.32765441 -0.91159175 -0.85543012]\n",
            " [ 1.         -1.63429578 -0.27121019 -1.04454346 -0.96873498 -1.47088951\n",
            "  -0.32765441 -0.94494276 -0.85543012]\n",
            " [ 1.          0.45904597  2.05258631 -1.01782678 -0.93700995  0.39976925\n",
            "   2.18788296 -0.93557238 -0.8506143 ]\n",
            " [ 1.          0.30014544  3.16800863 -0.92373761 -0.81010984  0.23926525\n",
            "   3.62813008 -0.89669827 -0.81208774]\n",
            " [ 1.         -0.15997522  1.79032928 -0.98878692 -0.81010984 -0.20943071\n",
            "   1.86963349 -0.92450258 -0.81208774]\n",
            " [ 1.         -0.59522449  0.80769533 -0.95742386 -0.8841349  -0.61094151\n",
            "   0.7516471  -0.91159175 -0.83754279]\n",
            " [ 1.          0.30014544  1.53471166 -0.84939556 -0.8841349   0.23926525\n",
            "   1.56729309 -0.86039688 -0.83754279]\n",
            " [ 1.         -0.59522449  1.53471166 -0.92373761 -0.8841349  -0.61094151\n",
            "   1.56729309 -0.89669827 -0.83754279]\n",
            " [ 1.         -0.15997522  0.57863539 -0.84939556 -0.93700995 -0.20943071\n",
            "   0.50886375 -0.86039688 -0.8506143 ]\n",
            " [ 1.         -0.59522449  1.28573347 -0.92373761 -0.81010984 -0.61094151\n",
            "   1.28045384 -0.89669827 -0.81208774]\n",
            " [ 1.         -1.2653702   1.04339469 -1.06893695 -0.93700995 -1.1823901\n",
            "   1.00870782 -0.95275535 -0.8506143 ]\n",
            " [ 1.         -0.59522449  0.35621487 -0.84939556 -0.71493475 -0.61094151\n",
            "   0.27994985 -0.86039688 -0.7701213 ]\n",
            " [ 1.         -1.00560238  0.57863539 -0.76576074 -0.93700995 -0.96788854\n",
            "   0.50886375 -0.81446548 -0.8506143 ]\n",
            " [ 1.         -0.73478061 -0.27121019 -0.88772818 -0.93700995 -0.73474593\n",
            "  -0.32765441 -0.87968052 -0.8506143 ]\n",
            " [ 1.         -0.73478061  0.57863539 -0.88772818 -0.81010984 -0.73474593\n",
            "   0.50886375 -0.87968052 -0.81208774]\n",
            " [ 1.         -0.45290489  0.80769533 -0.92373761 -0.93700995 -0.48218556\n",
            "   0.7516471  -0.89669827 -0.8506143 ]\n",
            " [ 1.         -0.45290489  0.57863539 -0.95742386 -0.93700995 -0.48218556\n",
            "   0.50886375 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -1.13686804  0.14043376 -0.88772818 -0.93700995 -1.0774209\n",
            "   0.06449747 -0.87968052 -0.8506143 ]\n",
            " [ 1.         -1.00560238 -0.06870792 -0.88772818 -0.93700995 -0.96788854\n",
            "  -0.13790131 -0.87968052 -0.8506143 ]\n",
            " [ 1.         -0.15997522  0.57863539 -0.92373761 -0.81010984 -0.20943071\n",
            "   0.50886375 -0.89669827 -0.81208774]\n",
            " [ 1.         -0.45290489  2.32148276 -0.92373761 -0.96873498 -0.48218556\n",
            "   2.52244943 -0.89669827 -0.85543012]\n",
            " [ 1.         -0.00936515  2.59701863 -0.95742386 -0.93700995 -0.06523764\n",
            "   2.87374082 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -0.87157324 -0.06870792 -0.92373761 -0.96873498 -0.85369591\n",
            "  -0.13790131 -0.89669827 -0.85543012]\n",
            " [ 1.         -0.73478061  0.14043376 -1.01782678 -0.93700995 -0.73474593\n",
            "   0.06449747 -0.93557238 -0.8506143 ]\n",
            " [ 1.         -0.00936515  0.80769533 -0.98878692 -0.93700995 -0.06523764\n",
            "   0.7516471  -0.92450258 -0.8506143 ]\n",
            " [ 1.         -0.87157324 -0.06870792 -0.92373761 -0.96873498 -0.85369591\n",
            "  -0.13790131 -0.89669827 -0.85543012]\n",
            " [ 1.         -1.51408407 -0.27121019 -0.98878692 -0.93700995 -1.37902731\n",
            "  -0.32765441 -0.92450258 -0.8506143 ]\n",
            " [ 1.         -0.59522449  0.57863539 -0.92373761 -0.93700995 -0.61094151\n",
            "   0.50886375 -0.89669827 -0.8506143 ]\n",
            " [ 1.         -0.73478061  0.80769533 -0.98878692 -0.8841349  -0.73474593\n",
            "   0.7516471  -0.92450258 -0.83754279]\n",
            " [ 1.         -1.39110888 -1.50282233 -0.98878692 -0.8841349  -1.2828932\n",
            "  -1.33611294 -0.92450258 -0.83754279]\n",
            " [ 1.         -1.51408407  0.14043376 -0.98878692 -0.93700995 -1.37902731\n",
            "   0.06449747 -0.92450258 -0.8506143 ]\n",
            " [ 1.         -0.73478061  0.80769533 -0.88772818 -0.59860964 -0.73474593\n",
            "   0.7516471  -0.87968052 -0.70751563]\n",
            " [ 1.         -0.59522449  1.53471166 -0.76576074 -0.81010984 -0.61094151\n",
            "   1.56729309 -0.81446548 -0.81208774]\n",
            " [ 1.         -1.00560238 -0.27121019 -0.95742386 -0.8841349  -0.96788854\n",
            "  -0.32765441 -0.91159175 -0.83754279]\n",
            " [ 1.         -0.59522449  1.53471166 -0.88772818 -0.93700995 -0.61094151\n",
            "   1.56729309 -0.87968052 -0.8506143 ]\n",
            " [ 1.         -1.2653702   0.14043376 -0.95742386 -0.93700995 -1.1823901\n",
            "   0.06449747 -0.91159175 -0.8506143 ]\n",
            " [ 1.         -0.3078218   1.28573347 -0.92373761 -0.93700995 -0.34838099\n",
            "   1.28045384 -0.89669827 -0.8506143 ]\n",
            " [ 1.         -0.73478061  0.35621487 -0.95742386 -0.93700995 -0.73474593\n",
            "   0.27994985 -0.91159175 -0.8506143 ]\n",
            " [ 1.          2.58140434  0.14043376  1.38086618  1.09339191  2.79281438\n",
            "   0.06449747  1.47417407  1.0316836 ]\n",
            " [ 1.          1.47048238  0.14043376  1.16713276  1.4000672   1.4844455\n",
            "   0.06449747  1.1744634   1.46579544]\n",
            " [ 1.          2.38934196 -0.06870792  1.60389235  1.4000672   2.55832871\n",
            "  -0.13790131  1.8005089   1.46579544]\n",
            " [ 1.         -0.00936515 -1.50282233  0.67345503  0.80786665 -0.06523764\n",
            "  -1.33611294  0.53423252  0.65536162]\n",
            " [ 1.          1.64872732 -0.65629647  1.27283787  1.4000672   1.68640641\n",
            "  -0.67085529  1.32106153  1.46579544]\n",
            " [ 1.          0.30014544 -0.65629647  1.16713276  0.80786665  0.23926525\n",
            "  -0.67085529  1.1744634   0.65536162]\n",
            " [ 1.          1.29500093  0.35621487  1.38086618  1.7278925   1.28869826\n",
            "   0.27994985  1.47417407  1.96182496]\n",
            " [ 1.         -0.87157324 -1.346796    0.07988017  0.07819098 -0.85369591\n",
            "  -1.22345766 -0.12813797 -0.16814372]\n",
            " [ 1.          1.82973575 -0.46707304  1.27283787  0.80786665  1.89467811\n",
            "  -0.50516976  1.32106153  0.65536162]\n",
            " [ 1.         -0.45290489 -0.83888048  0.58168906  1.09339191 -0.48218556\n",
            "  -0.82511892  0.42374696  1.0316836 ]\n",
            " [ 1.         -0.73478061 -1.93106483  0.23785704  0.07819098 -0.73474593\n",
            "  -1.61941684  0.03561952 -0.16814372]\n",
            " [ 1.          0.62070999 -0.27121019  0.86395656  1.4000672   0.56590439\n",
            "  -0.32765441  0.7723394   1.46579544]\n",
            " [ 1.          0.78513749 -1.65220925  0.67345503  0.07819098  0.73776778\n",
            "  -1.43938595  0.53423252 -0.16814372]\n",
            " [ 1.          0.95232848 -0.46707304  1.38086618  1.09339191  0.91545649\n",
            "  -0.50516976  1.47417407  1.0316836 ]\n",
            " [ 1.          0.1440084  -0.46707304  0.32033026  0.80786665  0.08429532\n",
            "  -0.50516976  0.1248624   0.65536162]\n",
            " [ 1.          2.01350767 -0.06870792  1.06375084  1.09339191  2.10935766\n",
            "  -0.13790131  1.03423809  1.0316836 ]\n",
            " [ 1.          0.1440084  -0.27121019  1.16713276  1.4000672   0.08429532\n",
            "  -0.32765441  1.1744634   1.46579544]\n",
            " [ 1.          0.45904597 -0.83888048  0.7675442   0.07819098  0.39976925\n",
            "  -0.82511892  0.65038279 -0.16814372]\n",
            " [ 1.          1.12228296 -1.65220925  1.16713276  1.4000672   1.09906762\n",
            "  -1.43938595  1.1744634   1.46579544]\n",
            " [ 1.          0.1440084  -1.18413024  0.58168906  0.30026618  0.08429532\n",
            "  -1.10101218  0.42374696  0.0595758 ]\n",
            " [ 1.          0.62070999  0.14043376  1.49121767  2.44699316  0.56590439\n",
            "   0.06449747  1.63394265  3.15614849]\n",
            " [ 1.          0.95232848 -0.65629647  0.67345503  0.80786665  0.91545649\n",
            "  -0.67085529  0.53423252  0.65536162]\n",
            " [ 1.          1.29500093 -1.18413024  1.60389235  1.4000672   1.28869826\n",
            "  -1.10101218  1.8005089   1.46579544]\n",
            " [ 1.          0.95232848 -0.65629647  1.38086618  0.54349141  0.91545649\n",
            "  -0.67085529  1.47417407  0.33270163]\n",
            " [ 1.          1.47048238 -0.46707304  0.9626921   0.80786665  1.4844455\n",
            "  -0.50516976  0.90024396  0.65536162]\n",
            " [ 1.          1.82973575 -0.27121019  1.06375084  1.09339191  1.89467811\n",
            "  -0.32765441  1.03423809  1.0316836 ]\n",
            " [ 1.          2.20004307 -0.65629647  1.49121767  1.09339191  2.33054216\n",
            "  -0.67085529  1.63394265  1.0316836 ]\n",
            " [ 1.          2.01350767 -0.27121019  1.71889022  2.07686782  2.10935766\n",
            "  -0.32765441  1.97401442  2.52390003]\n",
            " [ 1.          0.78513749 -0.46707304  1.16713276  1.4000672   0.73776778\n",
            "  -0.50516976  1.1744634   1.46579544]\n",
            " [ 1.          0.30014544 -1.01482507  0.23785704  0.07819098  0.23926525\n",
            "  -0.96836857  0.03561952 -0.16814372]\n",
            " [ 1.         -0.00936515 -1.346796    0.49224627  0.30026618 -0.06523764\n",
            "  -1.22345766  0.3187845   0.0595758 ]\n",
            " [ 1.         -0.00936515 -1.346796    0.40512667  0.07819098 -0.06523764\n",
            "  -1.22345766  0.21920352 -0.16814372]\n",
            " [ 1.          0.45904597 -0.83888048  0.58168906  0.54349141  0.39976925\n",
            "  -0.82511892  0.42374696  0.33270163]\n",
            " [ 1.          0.78513749 -0.83888048  1.83621128  1.7278925   0.73776778\n",
            "  -0.82511892  2.15460083  1.96182496]\n",
            " [ 1.         -0.15997522 -0.27121019  1.16713276  1.4000672  -0.20943071\n",
            "  -0.32765441  1.1744634   1.46579544]\n",
            " [ 1.          0.78513749  0.57863539  1.16713276  1.7278925   0.73776778\n",
            "   0.50886375  1.1744634   1.96182496]\n",
            " [ 1.          2.01350767 -0.06870792  1.38086618  1.4000672   2.10935766\n",
            "  -0.13790131  1.47417407  1.46579544]\n",
            " [ 1.          1.29500093 -1.50282233  1.06375084  0.80786665  1.28869826\n",
            "  -1.33611294  1.03423809  0.65536162]\n",
            " [ 1.          0.1440084  -0.27121019  0.7675442   0.80786665  0.08429532\n",
            "  -0.32765441  0.65038279  0.65536162]\n",
            " [ 1.         -0.00936515 -1.18413024  0.67345503  0.80786665 -0.06523764\n",
            "  -1.10101218  0.53423252  0.65536162]\n",
            " [ 1.         -0.00936515 -1.01482507  1.06375084  0.54349141 -0.06523764\n",
            "  -0.96836857  1.03423809  0.33270163]\n",
            " [ 1.          0.95232848 -0.27121019  1.27283787  1.09339191  0.91545649\n",
            "  -0.32765441  1.32106153  1.0316836 ]\n",
            " [ 1.          0.45904597 -1.01482507  0.67345503  0.54349141  0.39976925\n",
            "  -0.96836857  0.53423252  0.33270163]\n",
            " [ 1.         -0.73478061 -1.50282233  0.07988017  0.07819098 -0.73474593\n",
            "  -1.33611294 -0.12813797 -0.16814372]\n",
            " [ 1.          0.1440084  -0.83888048  0.86395656  0.80786665  0.08429532\n",
            "  -0.82511892  0.7723394   0.65536162]\n",
            " [ 1.          0.30014544 -0.27121019  0.86395656  0.54349141  0.23926525\n",
            "  -0.32765441  0.7723394   0.33270163]\n",
            " [ 1.          0.30014544 -0.46707304  0.86395656  0.80786665  0.23926525\n",
            "  -0.50516976  0.7723394   0.65536162]\n",
            " [ 1.          1.12228296 -0.46707304  0.9626921   0.80786665  1.09906762\n",
            "  -0.50516976  0.90024396  0.65536162]\n",
            " [ 1.         -0.59522449 -1.18413024 -0.13966122  0.30026618 -0.61094151\n",
            "  -1.10101218 -0.33907782  0.0595758 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=Y.to_numpy()\n",
        "n = X.shape[0]                                  # giving n values to rows\n",
        "H = np.dot(Y*X, (Y*X).T)                        # Assigning Xi*Xj*Yi*Yj values to H\n",
        "q = np.repeat([-1.0], n)[..., None]             # giving -1 values to all rows\n",
        "A = Y.reshape(1, -1)                            # reshaping the values to A\n",
        "b = 0.0                                         \n",
        "G = np.negative(np.eye(n))\n",
        "h = np.zeros(n)                                 # assigning values h =0\n",
        "P = matrix(H)                                   # converting rows to matrix\n",
        "q = matrix(q)\n",
        "G = matrix(G)\n",
        "h = matrix(h)\n",
        "A = matrix(A,(1,n),'d')\n",
        "A = matrix(A)\n",
        "b = matrix(b)\n",
        "sol = solvers.qp(P, q, G, h, A, b)              # solving the Quadratic Program\n",
        "alphas = np.array(sol[\"x\"])\n",
        "w = np.dot((Y* alphas).T, X)[0]\n",
        "S = (alphas > 1e-5).flatten()\n",
        "b = np.mean(Y[S]-np.dot(X[S],w.reshape(-1,1)))\n",
        "print(\"W:\", w)\n",
        "print(\"b:\", b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTU2rW1QuUfD",
        "outputId": "ba872922-545a-4de0-cba7-63538c2eef2d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -4.2973e+00 -9.5330e+00  2e+02  1e+01  2e+00\n",
            " 1: -4.6415e+00 -4.5239e+00  4e+01  3e+00  3e-01\n",
            " 2: -2.3391e+00 -1.2103e+00  6e+00  4e-01  4e-02\n",
            " 3: -7.3145e-01 -8.3155e-01  1e+00  5e-02  6e-03\n",
            " 4: -5.6713e-01 -6.5807e-01  2e-01  6e-03  7e-04\n",
            " 5: -5.7969e-01 -6.0865e-01  5e-02  1e-03  2e-04\n",
            " 6: -5.8357e-01 -6.1346e-01  5e-02  1e-03  1e-04\n",
            " 7: -6.0378e-01 -6.0826e-01  5e-03  4e-05  5e-06\n",
            " 8: -6.0704e-01 -6.0710e-01  6e-05  5e-07  6e-08\n",
            " 9: -6.0708e-01 -6.0708e-01  6e-07  5e-09  6e-10\n",
            "10: -6.0708e-01 -6.0708e-01  6e-09  5e-11  6e-12\n",
            "Optimal solution found.\n",
            "W: [ 1.13996416e-16 -2.09378045e-01  1.52931055e-01 -6.30202148e-01\n",
            " -5.61673072e-01 -1.71044766e-01  1.46893037e-01 -4.74920745e-01\n",
            " -3.97400223e-01]\n",
            "b: -0.9762414864673589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred=w.dot(X.T)+b                                                             # predicting the value\n",
        "Y_pred[Y_pred<=0]=-1                                                            # replacing the value with respective labels\n",
        "Y_pred[Y_pred>=0]=1                                                             # replacing the value with respective labels\n",
        "print(Y_pred)                                                                   # printing the predicted label\n",
        "# predicting the results\n",
        "def comp(Y1,Y2):                                                                # function to check number of correct predictions\n",
        "  Y1=np.asarray(Y1,dtype='int64')                                               # assigning Y1 as an array\n",
        "  Y2=np.asarray(Y2,dtype='int64')                                               # assigning Y2 as an array\n",
        "  correct=0                                                                     # variable for checking no of correct predictions\n",
        "  incorrect=0                                                                   # variable for checking no of incorrect predictions\n",
        "  for i in range(len(Y1)):                                                      \n",
        "    if(Y1[i]==Y2[i]):                                                           # if prediction is correct then correct++\n",
        "      correct+=1                                                                \n",
        "    else:                                                                       # if prediction is incorrect then correct++\n",
        "      incorrect+=1\n",
        "  correctperc=(correct*100)/len(Y1)                                             # percentage of correct predictions among all\n",
        "  return [correct,incorrect,correctperc]                                        # returning no of correct predictions,no of incorrect predictions,percentage of correct predicitons\n",
        "correct,incorrect,perc=comp(Y,Y_pred)                                           # calling the function to evaluate the model\n",
        "print(\"Correct Predictions : \",correct)                                         # printing number of correct predictions\n",
        "print(\"Incorrect Predictions : \",incorrect)                                     # printing number of incorrect predictions\n",
        "print(\"Percentage of correct prediction : \",perc)                               # printing the percentage of correct predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNZYenWPuf7d",
        "outputId": "a0898a1f-4d03-49c4-92b9-108cc2d534d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            "Correct Predictions :  99\n",
            "Incorrect Predictions :  0\n",
            "Percentage of correct prediction :  100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9GATxnsJNYda"
      }
    }
  ]
}